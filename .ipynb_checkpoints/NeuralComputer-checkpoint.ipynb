{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\"Hybrid computing using a neural network with dynamic external memory\"</h1>\n",
    "<h4 align=\"center\">by Google DeepMind</h4>\n",
    "\n",
    "Paper available here: http://www.nature.com/nature/journal/vaop/ncurrent/full/nature20101.html\n",
    "<br><hr><br>\n",
    "This paper, published in Nature 2016, develops the idea of a differentiable neural computer (DNC). This paper is based heavily on the work Alex Graves and Greg Wayne previously did on \"Neural Turing Machines\" (link: https://arxiv.org/abs/1410.5401). I'd *highly* recommend that anybody attempting to really understand DNCs read and understand his paper first.\n",
    "\n",
    "DNCs can be viewed as a more general type of LSTM (http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf) where the network learns how to use memory to understand data rather than attempting to learn the raw sequence relationships. This allows the network to be trained on a small amount of data and generalize to large amount of data without training, as well as handling inputs that were not necessarily seen during training --- a huge divergence from what was previously possible.\n",
    "\n",
    "These findings are facilitated by the author's novel framework of memory which is fully differentiable (thus the name). Because of this property, the memory structure is able to be coupled with a neural network and trained by gradient descent or any other optimization method.\n",
    "\n",
    "I'm going to write this tutorial in the simplest way I can think of to enable as broad of an audience as possible. Thus, some of the results you see here might not be as optimal as the well polished results in the paper. I'll expect that you have read the main parts of the paper, and this will serve as a walkthrough for the methods section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "<br>\n",
    "Before we begin, let's go over some of the foundational concepts to allow you understand all of the moving parts.\n",
    "\n",
    "First, the paper talks about $N-1$ dimensional simplex $$\\mathcal{S}_N = \\big\\{\\alpha \\in \\mathbb{R}^N: \\alpha_i \\in [0, 1], \\sum_{i=1}^{N} \\alpha_i = 1\\big\\}$$ This is just a probability distribution over N locations in a vector (if you add up every element in the vector, the sum should be 1). There is also mention of a \"non-negative orthant of $\\mathbb{R}^N$ with the unit simplex as a boundary\". If you're not familiar with the definition of the non-negative orthant or the unit-simplex, I encourage you to look up these definitons. We can skip this discussion and look at the equation given, namely $$\\Delta_N = \\big\\{\\alpha \\in \\mathbb{R}^N: \\alpha_i \\in [0, 1], \\sum_{i=1}^{N} \\alpha_i \\le 1\\big\\}$$ This is *almost* the same formula as above, except the very important observation that the sum can be equal *or less than* 1. Not that no number is negative in the vector, so this sum will not be less than 0 either.\n",
    "\n",
    "\n",
    "<center>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Symbol</th>\n",
    "        <th>Restraints</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>$\\mathcal{N}$</center></td>\n",
    "        <td></td>\n",
    "        <td>Controller neural network (optimally, a recurrent network), that makes predictions and learns to use the external memory. The authors liken this to the CPU in a computer</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>$N$</center></td>\n",
    "        <td><center>$\\in \\mathbb{R}$</center></td>\n",
    "        <td>Number of memory locations in $M$, arbitrarily chosen.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>$W$</center></td>\n",
    "        <td><center>$\\in \\mathbb{R}$</center></td>\n",
    "        <td>Learnable weight matrices, also arbitrarily chosen.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>$M_t$</center></td>\n",
    "        <td><center>$\\in \\mathbb{R}^{N\\text{x}W}$</center></td>\n",
    "        <td>Memory matrix at time $t$.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>$x_t$</center></td>\n",
    "        <td><center>$\\in \\mathbb{R}^X$</center></td>\n",
    "        <td>Input vector from the dataset (supervised) or environment (reinforcement).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>$y_t$</center></td>\n",
    "        <td><center>$\\in \\mathbb{R}^Y$</center></td>\n",
    "        <td>Output vector that represents a predictive distribution (supervised) or an action distribution (reinforcement).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>$z_t$</center></td>\n",
    "        <td><center>$\\in \\mathbb{R}^Z$</center></td>\n",
    "        <td>Target output vector (only applicable to supervised learning)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>$R_t$</center></td>\n",
    "        <td><center>$\\in \\mathbb{R}^W$</center></td>\n",
    "        <td>Read vectors $r^{1}_{t-1}, \\cdots, r^{R}_{t-1}$ which represents what we read from memory during the last timestep.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg color-interpolation=\"auto\" color-rendering=\"auto\" fill=\"black\" fill-opacity=\"1\" font-family=\"'Dialog'\" font-size=\"12px\" font-style=\"normal\" font-weight=\"normal\" height=\"500\" image-rendering=\"auto\" shape-rendering=\"auto\" stroke=\"black\" stroke-dasharray=\"none\" stroke-dashoffset=\"0\" stroke-linecap=\"square\" stroke-linejoin=\"miter\" stroke-miterlimit=\"10\" stroke-opacity=\"1\" stroke-width=\"1\" text-rendering=\"auto\" width=\"628\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "  <!--Generated by ySVG 2.5-->\n",
       "  <defs id=\"genericDefs\"/>\n",
       "  <g>\n",
       "    <defs id=\"defs1\">\n",
       "      <clipPath clipPathUnits=\"userSpaceOnUse\" id=\"clipPath1\">\n",
       "        <path d=\"M0 0 L628 0 L628 500 L0 500 L0 0 Z\"/>\n",
       "      </clipPath>\n",
       "      <clipPath clipPathUnits=\"userSpaceOnUse\" id=\"clipPath2\">\n",
       "        <path d=\"M557 45 L1185 45 L1185 545 L557 545 L557 45 Z\"/>\n",
       "      </clipPath>\n",
       "      <clipPath clipPathUnits=\"userSpaceOnUse\" id=\"clipPath3\">\n",
       "        <path d=\"M471.79 -25.0218 L471.79 602.9782 L-28.21 602.9782 L-28.21 -25.0218 L471.79 -25.0218 Z\"/>\n",
       "      </clipPath>\n",
       "      <clipPath clipPathUnits=\"userSpaceOnUse\" id=\"clipPath4\">\n",
       "        <path d=\"M196.1602 -23.5032 L196.1602 604.4968 L-303.8398 604.4968 L-303.8398 -23.5032 L196.1602 -23.5032 Z\"/>\n",
       "      </clipPath>\n",
       "      <clipPath clipPathUnits=\"userSpaceOnUse\" id=\"clipPath5\">\n",
       "        <path d=\"M484.3379 -537.5218 L484.3379 90.4782 L-15.6621 90.4782 L-15.6621 -537.5218 L484.3379 -537.5218 Z\"/>\n",
       "      </clipPath>\n",
       "      <clipPath clipPathUnits=\"userSpaceOnUse\" id=\"clipPath6\">\n",
       "        <path d=\"M197.3906 -536.0032 L197.3906 91.9968 L-302.6094 91.9968 L-302.6094 -536.0032 L197.3906 -536.0032 Z\"/>\n",
       "      </clipPath>\n",
       "    </defs>\n",
       "    <g fill=\"white\" shape-rendering=\"geometricPrecision\" stroke=\"white\" text-rendering=\"geometricPrecision\" transform=\"translate(-557,-45)\">\n",
       "      <rect clip-path=\"url(#clipPath2)\" height=\"500\" stroke=\"none\" width=\"628\" x=\"557\" y=\"45\"/>\n",
       "    </g>\n",
       "    <g font-family=\"sans-serif\" shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(-0,-1,1,-0,25.0218,471.79)\">\n",
       "      <text clip-path=\"url(#clipPath3)\" stroke=\"none\" x=\"5\" xml:space=\"preserve\" y=\"16.1387\">Memory Reads (for last timestep)</text>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-dasharray=\"6,2\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <rect clip-path=\"url(#clipPath2)\" fill=\"none\" height=\"233.75\" width=\"85\" x=\"572.4876\" y=\"294.125\"/>\n",
       "    </g>\n",
       "    <g fill=\"white\" shape-rendering=\"geometricPrecision\" stroke=\"white\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"105\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"105\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"white\" shape-rendering=\"geometricPrecision\" stroke=\"white\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"151\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"151\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"white\" shape-rendering=\"geometricPrecision\" stroke=\"white\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"197\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"197\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"white\" shape-rendering=\"geometricPrecision\" stroke=\"white\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"243\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"243\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"red\" shape-rendering=\"geometricPrecision\" stroke=\"red\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"342\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"342\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"red\" shape-rendering=\"geometricPrecision\" stroke=\"red\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"388\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"388\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"red\" shape-rendering=\"geometricPrecision\" stroke=\"red\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"434\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"434\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"red\" shape-rendering=\"geometricPrecision\" stroke=\"red\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"480\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"627\" cy=\"480\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g font-family=\"sans-serif\" shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(-0,-1,1,-0,23.5032,196.1602)\">\n",
       "      <text clip-path=\"url(#clipPath4)\" stroke=\"none\" x=\"5\" xml:space=\"preserve\" y=\"16.1387\">Environment inputs</text>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-dasharray=\"6,2\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <rect clip-path=\"url(#clipPath2)\" fill=\"none\" height=\"233.75\" width=\"85\" x=\"572.4876\" y=\"60.375\"/>\n",
       "      <text clip-path=\"url(#clipPath2)\" font-family=\"sans-serif\" stroke=\"none\" stroke-dasharray=\"none\" x=\"855.2444\" xml:space=\"preserve\" y=\"295.4543\">LSTM</text>\n",
       "      <rect clip-path=\"url(#clipPath2)\" fill=\"none\" height=\"112.5\" stroke-dasharray=\"none\" width=\"222.5\" x=\"759.9876\" y=\"235.05\"/>\n",
       "    </g>\n",
       "    <g font-family=\"sans-serif\" shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(-0,-1,1,-0,537.5218,484.3379)\">\n",
       "      <text clip-path=\"url(#clipPath5)\" stroke=\"none\" x=\"5\" xml:space=\"preserve\" y=\"16.1387\">Memory interactions for this timestep</text>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-dasharray=\"6,2\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <rect clip-path=\"url(#clipPath2)\" fill=\"none\" height=\"233.75\" width=\"85\" x=\"1084.9876\" y=\"294.125\"/>\n",
       "    </g>\n",
       "    <g fill=\"white\" shape-rendering=\"geometricPrecision\" stroke=\"white\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"105\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"105\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"white\" shape-rendering=\"geometricPrecision\" stroke=\"white\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"151\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"151\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"white\" shape-rendering=\"geometricPrecision\" stroke=\"white\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"197\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"197\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"white\" shape-rendering=\"geometricPrecision\" stroke=\"white\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"243\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"243\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"blue\" shape-rendering=\"geometricPrecision\" stroke=\"blue\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"342\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"342\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"blue\" shape-rendering=\"geometricPrecision\" stroke=\"blue\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"388\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"388\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"blue\" shape-rendering=\"geometricPrecision\" stroke=\"blue\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"434\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"434\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g fill=\"blue\" shape-rendering=\"geometricPrecision\" stroke=\"blue\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"480\" r=\"15\" stroke=\"none\"/>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <circle clip-path=\"url(#clipPath2)\" cx=\"1139.5\" cy=\"480\" fill=\"none\" r=\"15\"/>\n",
       "    </g>\n",
       "    <g font-family=\"sans-serif\" shape-rendering=\"geometricPrecision\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(-0,-1,1,-0,536.0032,197.3906)\">\n",
       "      <text clip-path=\"url(#clipPath6)\" stroke=\"none\" x=\"5\" xml:space=\"preserve\" y=\"16.1387\">Environment output</text>\n",
       "    </g>\n",
       "    <g shape-rendering=\"geometricPrecision\" stroke-dasharray=\"6,2\" stroke-linecap=\"butt\" stroke-miterlimit=\"1.45\" text-rendering=\"geometricPrecision\" transform=\"matrix(1,0,0,1,-557,-45)\">\n",
       "      <rect clip-path=\"url(#clipPath2)\" fill=\"none\" height=\"233.75\" width=\"85\" x=\"1084.9876\" y=\"60.375\"/>\n",
       "      <path clip-path=\"url(#clipPath2)\" d=\"M657.4876 196.1656 L752.6788 238.5327\" fill=\"none\" stroke-dasharray=\"none\"/>\n",
       "      <path clip-path=\"url(#clipPath2)\" d=\"M759.9876 241.7856 L751.0576 232.3382 L751.7652 238.1261 L746.9913 241.4742 Z\" stroke=\"none\" stroke-dasharray=\"none\"/>\n",
       "      <path clip-path=\"url(#clipPath2)\" d=\"M657.4876 391.1473 L752.7394 346.6531\" fill=\"none\" stroke-dasharray=\"none\"/>\n",
       "      <path clip-path=\"url(#clipPath2)\" d=\"M759.9876 343.2673 L746.9992 343.8159 L751.8334 347.0763 L751.2314 352.8761 Z\" stroke=\"none\" stroke-dasharray=\"none\"/>\n",
       "      <path clip-path=\"url(#clipPath2)\" d=\"M982.4876 343.2673 L1077.7394 387.7615\" fill=\"none\" stroke-dasharray=\"none\"/>\n",
       "      <path clip-path=\"url(#clipPath2)\" d=\"M1084.9875 391.1473 L1076.2313 381.5385 L1076.8334 387.3383 L1071.9991 390.5988 Z\" stroke=\"none\" stroke-dasharray=\"none\"/>\n",
       "      <path clip-path=\"url(#clipPath2)\" d=\"M982.4959 253.1473 L991.2571 250.143 L1029.7703 236.0669 L1057.9563 224.5437 L1078.1821 214.5512 L1078.2667 214.4979\" fill=\"none\" stroke-dasharray=\"none\"/>\n",
       "      <path clip-path=\"url(#clipPath2)\" d=\"M1085.0736 210.2948 L1072.2363 212.3452 L1077.4159 215.0233 L1077.4902 220.8538 Z\" stroke=\"none\" stroke-dasharray=\"none\"/>\n",
       "    </g>\n",
       "  </g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import SVG, display\n",
    "display(SVG('diagram.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the more interesting experiments in the paper is question answering: here the authors use the \"bAbi\" training set, which is distributed by Jase Weston at Facebook. Let's prepare that data while we are still at the preliminary part of this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import nltk\n",
    "\n",
    "\n",
    "if not os.path.exists(\"bAbi\"):\n",
    "    !wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\n",
    "    !mkdir bAbi && tar -xzf ./tasks_1-20_v1-2.tar.gz -C bAbi --strip-components 1\n",
    "    \n",
    "unique_words = set([''])\n",
    "unique_answers = set()\n",
    "for file in glob.glob(\"bAbi/en-10k/*\"):\n",
    "    stories = []\n",
    "    with open(file, 'r') as f:\n",
    "        lines = [str(re.sub(\"\\d\", \"\", line)).strip() for line in f.readlines()]\n",
    "        story = []\n",
    "        for line in lines:\n",
    "            line = line.replace(\",\", \" , \").replace(\"?\", \" ? \").replace(\".\", \" . \").replace(\",\", \" , \").replace('\\'','')\n",
    "            \n",
    "            if \"\\t\" not in line:\n",
    "                # not a question\n",
    "                words = line.split()\n",
    "                unique_words = unique_words.union(set(words))\n",
    "                story.extend(words)\n",
    "            else:\n",
    "                # question\n",
    "                [line, answer] = line.split(\"\\t\")\n",
    "                words = line.split()\n",
    "                unique_words = unique_words.union(set(words))\n",
    "                unique_answers = unique_answers.union(set([answer]))\n",
    "                story.extend(words)\n",
    "                this_story = {\n",
    "                        \"seq\": story,\n",
    "                        \"answer\": answer\n",
    "                }\n",
    "                stories.append(this_story)\n",
    "                story = []\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input will be a sequence of 26 words, padding by zeros at the beginning when needed.\n",
      "There are 25 unique words, which will be mapped to one-hot encoded vectors.\n",
      "There are 3 unique answers, which will be mapped to one-hot encoded vectors.\n",
      "\n",
      "Encoding sequences...\n",
      "Splitting training/testing set...\n",
      "\n",
      "X_train: (750, 26, 25)\n",
      "y_train: (750, 3)\n",
      "X_test: (250, 26, 25)\n",
      "y_test: (250, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "longest_story = max(stories, key=lambda s: len(s[\"seq\"]))\n",
    "longest_story_len = len(longest_story[\"seq\"])\n",
    "print(\"Input will be a sequence of {} words, \"\\\n",
    "      \"padding by zeros at the beginning when \"\\\n",
    "      \"needed.\".format(len(longest_story[\"seq\"])))\n",
    "\n",
    "num_words = len(unique_words)\n",
    "num_answers = len(unique_answers)\n",
    "print(\"There are {} unique words, which will be mapped to one-hot encoded vectors.\".format(num_words))\n",
    "print(\"There are {} unique answers, which will be mapped to one-hot encoded vectors.\".format(num_answers))\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "word_encoder = lb.fit(list(unique_words))\n",
    "\n",
    "lba = preprocessing.LabelBinarizer()\n",
    "answer_encoder = lba.fit(list(unique_answers))\n",
    "\n",
    "def pad_and_encode_seq(seq, seq_len=longest_story_len):\n",
    "    if len(seq) > seq_len:\n",
    "        raise RuntimeError(\"Should never see a sequence greater than {} length\".format(seq_len))\n",
    "    return word_encoder.transform((['' for i in range(seq_len-len(seq))]) + seq)\n",
    "\n",
    "print()\n",
    "print(\"Encoding sequences...\")\n",
    "X = []\n",
    "y = []\n",
    "from collections import defaultdict\n",
    "\n",
    "for story in stories:\n",
    "    X.append(np.array(pad_and_encode_seq(story[\"seq\"])))\n",
    "    y.append(answer_encoder.transform([story[\"answer\"]])[0])\n",
    "   \n",
    "print(\"Splitting training/testing set...\")\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "print()\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try training this using an LSTM model --- see if we can get the same 37% error rate. I've run this for 100 iterations and the returns for training past iteration 10 are small. To keep the training time palettable for this tutorial, I've truncated this to 10 epochs and a batch size of 64. You can change \"easy_mode\" to False below if you would like to recreate the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 5s - loss: 2.4912 - acc: 0.4160 - val_loss: 1.4163 - val_acc: 0.4280\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s - loss: 1.2710 - acc: 0.3960 - val_loss: 1.9138 - val_acc: 0.4480\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s - loss: 1.3330 - acc: 0.4320 - val_loss: 1.0654 - val_acc: 0.4280\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s - loss: 1.4722 - acc: 0.4147 - val_loss: 1.3468 - val_acc: 0.4280\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s - loss: 1.3576 - acc: 0.4107 - val_loss: 1.4180 - val_acc: 0.4480\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s - loss: 1.5035 - acc: 0.4333 - val_loss: 1.1171 - val_acc: 0.4280\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s - loss: 1.4555 - acc: 0.3987 - val_loss: 1.1153 - val_acc: 0.4280\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s - loss: 1.2697 - acc: 0.4227 - val_loss: 1.4137 - val_acc: 0.4280\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 5s - loss: 1.5228 - acc: 0.4107 - val_loss: 1.5780 - val_acc: 0.4360\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 4s - loss: 2.0367 - acc: 0.3387 - val_loss: 1.3097 - val_acc: 0.4480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12f29c0b8>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "easy_mode = True\n",
    "if easy_mode:\n",
    "    batch_size=64\n",
    "    nb_epoch=10\n",
    "    lr = 0.01\n",
    "else:\n",
    "    batch_size=1\n",
    "    nb_epoch=100\n",
    "    lr = 0.0001\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(longest_story_len, num_words)))\n",
    "model.add(Dense(num_answers))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Optional for all you non tensorflow-ers\n",
    "callbacks = [TensorBoard(log_dir='./logs')]\n",
    "optimizer = RMSprop(lr=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, \n",
    "         nb_epoch=nb_epoch, \n",
    "         batch_size=batch_size, \n",
    "         validation_data=(X_test, y_test), \n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our model and see if it works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Julie went back to the park . Mary travelled to the cinema . Is Fred in the bedroom ?\n",
      "LSTM answers \"yes\"\n",
      "        Julie went to the bedroom . Julie went to the park . Is Julie in the park ?\n",
      "LSTM answers \"yes\"\n",
      "    Julie journeyed to the office . Bill is either in the kitchen or the kitchen . Is Julie in the office ?\n",
      "LSTM answers \"yes\"\n",
      "    Fred is in the bedroom . Fred is either in the office or the park . Is Fred in the office ?\n",
      "LSTM answers \"yes\"\n",
      "Bill is either in the bedroom or the office . Fred is either in the cinema or the bedroom . Is Fred in the bedroom ?\n",
      "LSTM answers \"no\"\n",
      "    Julie moved to the kitchen . Bill is either in the park or the kitchen . Is Julie in the park ?\n",
      "LSTM answers \"yes\"\n",
      "    Julie moved to the kitchen . Bill is either in the park or the kitchen . Is Julie in the park ?\n",
      "LSTM answers \"yes\"\n",
      "   Julie went back to the cinema . Bill is either in the kitchen or the cinema . Is Bill in the kitchen ?\n",
      "LSTM answers \"yes\"\n",
      "        Julie is in the school . Bill moved to the school . Is Julie in the school ?\n",
      "LSTM answers \"yes\"\n",
      "Julie is either in the cinema or the park . Bill is either in the office or the office . Is Mary in the office ?\n",
      "LSTM answers \"no\"\n",
      "    Fred is in the park . Mary is either in the kitchen or the bedroom . Is Fred in the park ?\n",
      "LSTM answers \"yes\"\n",
      "    Julie is either in the bedroom or the kitchen . Mary journeyed to the school . Is Julie in the bedroom ?\n",
      "LSTM answers \"yes\"\n",
      "        Julie is in the school . Bill is in the office . Is Bill in the kitchen ?\n",
      "LSTM answers \"yes\"\n",
      "        Mary is in the school . Bill is in the kitchen . Is Bill in the bedroom ?\n",
      "LSTM answers \"yes\"\n",
      "        Fred is in the bedroom . Julie journeyed to the cinema . Is Julie in the cinema ?\n",
      "LSTM answers \"yes\"\n",
      "        Julie journeyed to the bedroom . Fred went to the bedroom . Is Julie in the bedroom ?\n",
      "LSTM answers \"yes\"\n",
      "    Mary is either in the school or the cinema . Fred went to the school . Is Mary in the office ?\n",
      "LSTM answers \"yes\"\n",
      "        Fred travelled to the office . Julie moved to the school . Is Julie in the school ?\n",
      "LSTM answers \"yes\"\n",
      "    Julie is either in the park or the school . Bill moved to the kitchen . Is Julie in the office ?\n",
      "LSTM answers \"yes\"\n",
      "        Fred journeyed to the school . Bill is in the office . Is Fred in the school ?\n",
      "LSTM answers \"yes\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_indices = np.random.randint(0, X_test.shape[0]-1, size=20)\n",
    "X_ = X_test[random_indices]\n",
    "\n",
    "y_ = model.predict(X_)\n",
    "for X, y in zip(X_, y_):\n",
    "    print(' '.join(word_encoder.inverse_transform(X)))\n",
    "    print(\"LSTM answers \\\"{}\\\"\".format(answer_encoder.inverse_transform(np.array([y]))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get between 38-43% accuracy for this dataset. Kind of curious number, especially when you inspect that all of the answers are probably the same (sometimes it learns all \"yes\", others all \"no\"). A random guess would be 33% if the answers were independently and identically distributed, so this is eerily close. Let's take random samples and see what our percentage would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked yes 42471 times (42.471%)\n",
      "Picked no 45016 times (45.016%)\n",
      "Picked maybe 12513 times (12.513%)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "total_samples = 100000\n",
    "results = defaultdict(int)\n",
    "for i in range(total_samples):\n",
    "    random_sample_index = np.random.randint(0, len(y_test)-1)\n",
    "    results[answer_encoder.inverse_transform(np.array([y_test[random_sample_index]]))[0]] += 1\n",
    "    \n",
    "for k, v in results.items():\n",
    "    print(\"Picked {} {} times ({}%)\".format(k, v, v/total_samples*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we get about the same percentage as your accuracy above. From this, we can deduce that this just answers the same thing every time without really learning anything. This isn't especially helpful for our application --- let's see if we can do better with a Differentiable Neural Computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import LSTM\n",
    "from keras.objectives import categorical_crossentropy\n",
    "\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "class Controller(object):\n",
    "    \n",
    "    def __init__(self, env_in_shape, env_out_shape, N, W, R):\n",
    "        \"\"\"Input and output sizes defined in methods (controller network).\"\"\"\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        K.set_session(self.session)\n",
    "        \n",
    "        self.env_in_shape = env_in_shape\n",
    "        self.reads_in_shape = W*R\n",
    "        self.env_out_shape = env_out_shape\n",
    "        self.int_out_dim = (W*R) + 3*W + 5*R + 3\n",
    "        \n",
    "        self.env_in = tf.placeholder(tf.float32, shape=env_in_shape, name=\"env_in\")\n",
    "        self.env_out = tf.placeholder(tf.float32, shape=env_out_shape, name=\"env_out\")\n",
    "        self.reads_in = tf.placeholder(tf.float32, shape=self.reads_in_shape, name=\"reads_in\")\n",
    "        \n",
    "        d1 = Dense(512, name=\"intmd_layer\")(self.env_in, self.reads_in)\n",
    "        \n",
    "        self.env_out_prime = Dense(env_out_shape, activation='softmax', name=\"env_out_prime\")(d1)\n",
    "        self.int_out = Dense(self.int_out_dim, activation='relu', name=\"int_out\")(d1)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(categorical_crossentropy(self.env_out, self.env_out_prime))\n",
    "        self.train_fn = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "        self.session.run(tf.initialize_all_variables())\n",
    "        \n",
    "    def feedforward(self, X, y, reads_in):\n",
    "        return self.session.run([self.int_out],\n",
    "                                 feed_dict={\n",
    "                                    self.env_in: X,\n",
    "                                    self.env_out: y,\n",
    "                                    self.reads_in: reads_in,\n",
    "                                    K.learning_phase(): 1\n",
    "                                })\n",
    "    \n",
    "    def train(self, X, y, reads_in):\n",
    "        return self.session.run([self.env_out_prime,\n",
    "                                 self.int_out,\n",
    "                                 self.loss,\n",
    "                                 self.train_fn],\n",
    "                                 feed_dict={\n",
    "                                    self.env_in: X,\n",
    "                                    self.env_out: y,\n",
    "                                    self.reads_in: reads_in,\n",
    "                                    K.learning_phase(): 1\n",
    "                                })\n",
    "    \n",
    "    def predict(self, X, reads_in):\n",
    "        return self.session.run([self.env_out_prime,\n",
    "                                 self.int_out,\n",
    "                                 self.loss,\n",
    "                                 self.env_out_prime],\n",
    "                                 feed_dict={\n",
    "                                    self.env_in: X,\n",
    "                                    self.reads_in: reads_in,\n",
    "                                    K.learning_phase(): 0\n",
    "                                })\n",
    "    \n",
    "    def get_dims(self):\n",
    "        return {\n",
    "            'env_in': self.env_in_dim,\n",
    "            'reads_in': self.reads_in_dim,\n",
    "            'env_out': self.env_out_dim,\n",
    "            'int_out': self.int_out_dim\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ensure that this controller compiles with fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-34172ca784be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mController\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-208-0343fad10d28>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_in_shape, env_out_shape, N, W, R)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"intmd_layer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreads_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_out_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_out_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"env_out_prime\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_out_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int_out\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/claymcleod/miniconda2/envs/python3/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    485\u001b[0m                                     '`layer.build(batch_input_shape)`')\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/claymcleod/miniconda2/envs/python3/lib/python3.5/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         self.W = self.init((input_dim, self.output_dim),\n\u001b[0;32m--> 695\u001b[0;31m                            name='{}_W'.format(self.name))\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             self.b = K.zeros((self.output_dim,),\n",
      "\u001b[0;32m/Users/claymcleod/miniconda2/envs/python3/lib/python3.5/site-packages/keras/initializations.py\u001b[0m in \u001b[0;36mglorot_uniform\u001b[0;34m(shape, name, dim_ordering)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mglorot_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'th'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfan_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(20, 10)\n",
    "y = np.random.randn(3)\n",
    "\n",
    "c = Controller(X.shape, y.shape, 256, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need some utility mathematical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def one_plus(x):\n",
    "    return 1 + np.log(1 + np.exp(x))\n",
    "    \n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def cos_sim(u, v):\n",
    "    return cosine_similarity(u, v)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We now have enough defined to create our differentiable neural computer class, which will handle all of the coupling between our controller and the memory network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def content_lookup(M, k, B):\n",
    "    \"\"\"Content lookup for a single read/write head.\n",
    "    \n",
    "    Args:\n",
    "        M (np.array): Memory matrix with dimensions (N, W).\n",
    "        k (np.array): Read/write key emitted by the controller\n",
    "            with dimensions (W,).\n",
    "        B/beta (int): Read/write strength emitted by the \n",
    "            controller which is an int. This represents how \n",
    "            strongly you want your head to attend to the closest \n",
    "            matching memory location (B=1 shows almost no \n",
    "            preference, B=100 will almost always single out\n",
    "            the closest matching location).\n",
    "            \n",
    "    Returns:\n",
    "        np.array: normalized probability distribution over \n",
    "            the locations in memory with dimensions (N,).\n",
    "            You can think of this as the attention that the\n",
    "            read head pays to each location based on the \n",
    "            content similarity.\n",
    "    \n",
    "    \"\"\"\n",
    "    locations = np.apply_along_axis(lambda x: np.exp(cos_sim(k, x.reshape(1, -1)) * B),1, M)\n",
    "    return locations / locations.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.62084722e-05,   7.55086933e-01,   2.44774442e-01,\n",
       "         4.62084722e-05,   4.62084722e-05])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.array([[0, 0, 0],\n",
    "              [1, 0, 0], \n",
    "              [0.5, 0.5, 0], \n",
    "              [0, 0, 1],\n",
    "              [0, 0, 0]])\n",
    "k = np.array([[0.8, 0.2, 0]])\n",
    "beta = 10.0\n",
    "content_lookup(M, k, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class DNC(object):\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, N=256, W=64, R=1):\n",
    "        self.controller = Controller((1, X_train.shape[2]), (1, y_train.shape[1]), N, W, R)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.N = N\n",
    "        self.W = W\n",
    "        self.R = R\n",
    "        self.reset_machine()\n",
    "        \n",
    "    def reset_machine(self):\n",
    "        \n",
    "        # Just for convenience\n",
    "        N = self.N\n",
    "        W = self.W\n",
    "        R = self.R\n",
    "        self.memory = np.zeros((N, W))\n",
    "        \n",
    "        #########################\n",
    "        ## Read head variables ##\n",
    "        #########################\n",
    "        \n",
    "        self.read_keys = np.zeros((R, W))\n",
    "        self.read_strengths = np.zeros((R,))\n",
    "        self.free_gates = np.zeros((R,))\n",
    "        self.read_modes = np.zeros((R, 3))\n",
    "        self.read_weighting = np.zeros((R, N))\n",
    "        \n",
    "        ##########################\n",
    "        ## Write head variables ##\n",
    "        ##########################\n",
    "        \n",
    "        self.write_key = np.zeros((W,))\n",
    "        self.write_strength = 0.0\n",
    "        self.write_gate = 0.0\n",
    "        self.write_weighting = np.zeros((N,))\n",
    "        \n",
    "        #####################\n",
    "        ## Other variables ##\n",
    "        #####################\n",
    "        \n",
    "        self.usage_vector = np.zeros((N,))\n",
    "        self.write_vector = np.zeros((W,))\n",
    "        self.erase_vector = np.zeros((W,))\n",
    "        self.allocation_gate = 0.0\n",
    "        self.precendence_weighting = np.zeros((N,))\n",
    "        self.linkage_matrix = np.zeros((N, N))\n",
    "        self.precedense = np.zeros((N,))\n",
    "    \n",
    "    def read_content_lookups(self):\n",
    "        return np.array([content_lookup(self.M, k, B) for (k, B) in zip(self.read_keys, self.read_strengths)])\n",
    "    \n",
    "    def write_content_lookup(self):\n",
    "        return content_lookup(self.M, self.write_keys, self.write_strengths)\n",
    "    \n",
    "    def update_linkage(self):\n",
    "        new_linkage_matrix = np.zeros((N, N))\n",
    "        \n",
    "        # Update linkages\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                if i == j:\n",
    "                    new_linkage_matrix[i][j] = 0.0 # diagonals == 0\n",
    "                else:\n",
    "                    new_linkage_matrix[i][j] = (1 - self.write_weighting[i] - self.write_weighting[j])*self.linkage_matrix[i][j] + self.write_weighting[i]*self.precedense[j]\n",
    "                    \n",
    "        self.linkage_matrix = new_linkage_matrix\n",
    "        \n",
    "        # Update precendense\n",
    "        self.precedense = (1 - np.sum(self.write_weighting))*self.precedense + self.write_weighting\n",
    "        \n",
    "    def update_read_weighting(self):\n",
    "        results = []\n",
    "        for (r_w, c_t, pi) in zip(self.read_weighting, self.read_content_lookups(), self.read_modes):\n",
    "            f_t = self.linkage_matrix * r_w\n",
    "            b_t = self.linkage_matrix.T * r_w\n",
    "            results.append(pi[0]*b_t + pi[1]*c_t + pi[2]*f_t)\n",
    "                \n",
    "        self.read_weightings = np.array(results)\n",
    "            \n",
    "    def get_rentention_vector(self):\n",
    "        \"\"\"Returns a vector with size (N,) which represents how much each\n",
    "        location will not be freed by the free gates\"\"\"\n",
    "        return np.prod(np.array([1-f*wr for (f, wr) in zip(self.free_gates, self.read_weighting)]))\n",
    "    \n",
    "    def update_usage_vector(self):\n",
    "        self.usage_vector = np.multiply(self.usage_vector + self.write_weighting \n",
    "                                        - np.multiply(self.usage_vector, self.write_weighting), \n",
    "                                        self.get_rentention_vector())\n",
    "    \n",
    "    def get_allocation_weighting(self):\n",
    "        self.update_usage_vector()\n",
    "        \n",
    "        phi = np.argsort(self.usage_vector)\n",
    "        allocation_vector = np.zeros((self.N))\n",
    "        for j in range(self.N):\n",
    "            allocation_vector[phi[j]] = (1 - self.usage_vector[phi[j]]) + np.prod(np.array([self.usage_vector[phi[i]] for i in range(j-1)]))\n",
    "        return allocation_vector\n",
    "    \n",
    "    def update_write_weighting(self):\n",
    "        wg = self.write_gate\n",
    "        ag = self.allocation_gate\n",
    "        aw = self.get_allocation_weighting()\n",
    "        c = self.write_content_lookup()\n",
    "        self.write_weighting = np.array(wg*(ag*aw + (1.0 - ag)*c)).sum(axis=0)\n",
    "    \n",
    "    def parse_interface(self, interface_input):\n",
    "        offset = 0 \n",
    "        i_in = np.array(interface_input)\n",
    "        i_in = i_in.reshape(i_in.shape[1])\n",
    "        \n",
    "        # For convenience\n",
    "        R = self.R\n",
    "        W = self.W\n",
    "        N = self.N\n",
    "        \n",
    "        self.read_keys = i_in[offset:R*W+offset].reshape(R, W)\n",
    "        offset += R*W\n",
    "        \n",
    "        self.read_strengths = one_plus(i_in[offset:R+offset].reshape(R,))\n",
    "        offset += R\n",
    "        \n",
    "        self.write_keys = i_in[offset:W+offset].reshape(W,)\n",
    "        offset += W\n",
    "        \n",
    "        self.write_strength = one_plus(i_in[offset:offset+1])\n",
    "        offset += 1\n",
    "        \n",
    "        self.erase_vector = sigmoid(i_in[offset:W+offset].reshape(W,))\n",
    "        offset += W\n",
    "        \n",
    "        self.write_vector = i_in[offset:W+offset].reshape(W,)\n",
    "        offset += W\n",
    "        \n",
    "        self.free_gates = sigmoid(i_in[offset:R+offset].reshape(R,))\n",
    "        offset += R\n",
    "        \n",
    "        self.allocation_gate = sigmoid(i_in[offset:offset+1])\n",
    "        offset += 1\n",
    "        \n",
    "        self.write_gate = sigmoid(i_in[offset:offset+1])\n",
    "        offset += 1\n",
    "        \n",
    "        self.read_modes = softmax(i_in[offset:R*3+offset].reshape((R, 3)))\n",
    "        offset += R*3\n",
    "        \n",
    "    def update_memory(self, interface_input):\n",
    "        self.parse_interface(interface_input)\n",
    "        self.update_read_weighting()\n",
    "        self.update_write_weighting()\n",
    "\n",
    "        w_t = self.write_weighting\n",
    "        et_T = self.erase_vector.T\n",
    "        vt_T = self.write_vector.T\n",
    "        self.memory = np.multiply(self.memory, np.ones(self.memory.shape) -  w_t*et_T) + w_t*vt_T\n",
    "        \n",
    "    def get_read_vectors(self):\n",
    "        results = []\n",
    "        for read_weighting in self.read_weighting:\n",
    "            results.append(self.memory.T * read_weighting)\n",
    "        return np.array(results)\n",
    "\n",
    "    def train(self):\n",
    "        shuffled_indices = np.arange(self.X_train.shape[0])\n",
    "        np.random.shuffle(shuffled_indices)\n",
    "        for index in list(shuffled_indices):\n",
    "            # Reset for each sequence\n",
    "            self.reset_machine()\n",
    "            for self.X_train[index]:\n",
    "                reads_in = self.get_read_vectors().flatten()\n",
    "                print(y)\n",
    "                X = X.reshape(1, X.shape[0])\n",
    "                print(X.shape)\n",
    "                [env_out, int_out, loss, _] = self.controller.train(X, y, reads_in)\n",
    "                self.update_memory(int_out)\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate a DNC based on our example graph $g$ that we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " ..., \n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n",
      "0\n",
      "(1, 25)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape () for Tensor 'env_out_52:0', which has shape '(1, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-1bb1a563561a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-190-659f3d6db47d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0menv_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreads_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-0a5e85b88297>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, reads_in)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_out\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreads_in\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreads_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                                 })\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/claymcleod/miniconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/claymcleod/miniconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    888\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape () for Tensor 'env_out_52:0', which has shape '(1, 3)'"
     ]
    }
   ],
   "source": [
    "computer = DNC(X_train, y_train, X_test, y_test, R=3)\n",
    "\n",
    "losses = []\n",
    "for i in range(0, 500):\n",
    "    losses.append(computer.train())\n",
    "        \n",
    "print(np.array(losses[-100]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(computer.memory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
